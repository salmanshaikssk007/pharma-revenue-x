ðŸ§¬ ModelN-Inspired Cloud ETL Pipeline

A deployable, interview-ready data engineering project simulating a pharmaceutical pricing workflow â€” inspired by Bayerâ€™s use of Model N, Snowflake, and AWS Glue. Built to demonstrate key cloud engineering skills across AWS, Snowflake, PySpark, Lambda, Step Functions, Terraform, and CI/CD.

â¸»

ðŸŽ¯ Purpose

This project simulates a real-world ETL pipeline for pharmaceutical rebate compliance using:
	â€¢	AWS Glue (PySpark) for data validation
	â€¢	Snowflake for clean warehousing
	â€¢	Lambda for event-based alerts
	â€¢	Step Functions for orchestration
	â€¢	Terraform for infrastructure as code
	â€¢	GitHub Actions for CI/CD

âœ… Built to align with Bayerâ€™s Cloud Engineer role.

â¸»

ðŸ—‚ Project Structure

pharma-revenue-x/
â”œâ”€â”€ glue/
â”‚   â””â”€â”€ modeln_etl_job.py          # PySpark ETL validation logic
â”œâ”€â”€ lambda/
â”‚   â””â”€â”€ alert_lambda.py           # Sends alerts if rebate violations detected
â”œâ”€â”€ data/
â”‚   â””â”€â”€ modeln_sample.json        # Simulated Model N input
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ glue.tf
â”‚   â”œâ”€â”€ lambda.tf
â”‚   â”œâ”€â”€ snowflake.tf
â”‚   â””â”€â”€ iam.tf
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml            # GitHub Actions CI/CD
â”œâ”€â”€ architecture.drawio           # Architecture Diagram
â””â”€â”€ README.md


â¸»

âš™ï¸ Flow Overview

graph TD
  A[S3 Raw JSON] --> B[Glue PySpark Job]
  B --> C[Validate rebate rules]
  C -->|valid| D[Snowflake Table]
  C -->|violations| E[S3 Alerts Bucket]
  E --> F[Lambda Function]
  F --> G[SNS Alert or Email]


â¸»

ðŸ“¥ Sample Input (modeln_sample.json)

[
  {
    "transaction_id": "T123",
    "customer_id": "C001",
    "sku": "SKU001",
    "unit_price": 100.00,
    "rebate_amount": 20.00,
    "transaction_date": "2025-07-20"
  }
]


â¸»

ðŸ”§ Tech Stack
	â€¢	AWS Glue â€“ PySpark-based data validation
	â€¢	Snowflake â€“ Cloud warehouse, optimized tables
	â€¢	AWS Lambda â€“ Trigger alerts
	â€¢	AWS Step Functions â€“ Orchestrates Glue + Lambda
	â€¢	Terraform â€“ Infrastructure as Code
	â€¢	GitHub Actions â€“ CI/CD for provisioning + updates
	â€¢	IAM + S3 + KMS â€“ Security best practices

â¸»

âœ… What It Demonstrates

Capability	Demo Element
Serverless ETL	Glue Job with PySpark
Data Quality Enforcement	Rebate rule validation
Lakehouse Pipeline	S3 â†’ Snowflake via Glue
Event-driven Design	Lambda triggers on violations
Workflow Orchestration	Step Functions
CI/CD Automation	GitHub Actions + Terraform
Security Best Practices	IAM roles + KMS (if added)


â¸»

ðŸ“ˆ Use Cases
	â€¢	Interview demo for Cloud/Data Engineer roles
	â€¢	Internal PoC for pharma pricing workflows
	â€¢	Extendable pipeline for AuroGenix Cloud Agents

â¸»

ðŸ“Œ Next Steps
	â€¢	Deploy Terraform infra to AWS
	â€¢	Run ETL job via Step Function
	â€¢	Visualize Snowflake output with Power BI / Tableau / Flask UI
	â€¢	Extend: add stored procedures, Snowflake alerts

â¸»

ðŸ§  Author

Built by Salman Shaik for Bayer Cloud Engineer interview readiness and future AuroGenix infra foundations.

â¸»

ðŸ›¡ Disclaimer

This is a simulated project for educational and professional demonstration purposes only. No proprietary data or logic from Bayer or Model N is used.